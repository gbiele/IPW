\documentclass[12pt]{article}

\usepackage[margin=1in]{geometry}


\usepackage{ifthen}
\newboolean{ismanus}
\setboolean{ismanus}{false}

\usepackage{url}
\usepackage{pgf}
\usepackage{tikz}
\usetikzlibrary{arrows,automata,calc}
\usepackage{verbatim}
\usepackage{tkz-tab}
\usepackage{subcaption} 
\usepackage[labelformat=parens,labelsep=quad,skip=3pt]{caption} 
\usepackage{array}
\newcolumntype{X}[1]{>{\centering\arraybackslash\baselineskip}p{#1}}
\usepackage{relsize}

\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
		\node[shape=circle,draw,inner sep=2pt] (char) {#1};}}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}

\usepackage{rotating}

\usepackage{caption}

\usepackage{textcomp}

\usepackage{multirow,makecell}

\newcommand{\elstodo}[1]{%
	\todo{\linespread{1}\tiny #1\par}%
}

%\SetWatermarkText{DRAFT - do not distribute}
%\SetWatermarkScale{.4}

\usepackage{adjustbox}
\usepackage{setspace}

\usepackage{longtable,lscape}

% to rotate table
\usepackage{rotating}

\usepackage{dcolumn}
\newcolumntype{L}{D{.}{.}{1,1}}

\usepackage{comment}

\usepackage{csquotes}
\usepackage[backend=bibtex,
            style=Nature,
            sorting=none,
            autocite=superscript]{biblatex}
\DeclareCaseLangs{}
\addbibresource{references/biblio.bib}

\AtEveryBibitem{\clearfield{month}\clearlist{language}}
\AtEveryCitekey{\clearfield{month}\clearlist{language}}

\usepackage[nofiglist,notablist]{endfloat}
\DeclareDelayedFloatFlavor{sidewaystable}{table}

\renewcommand{\baselinestretch}{2.0}

%opening
\title{Bias from Self Selection and Loss to Follow-up in Prospective Cohort Studies}
%\shorttitle{Bias From Self Selection and Loss to Follow Up}
\author{G. Biele \and K. Gustavson \and N. Czajkowski \and R. M. Nilsen \and T. Reichborn-Kjennerud \and P. Magnus \and C. Stoltenberg \and H. Aase}
%\affiliation{Norwegian Institute of Public Health}


\begin{document}
	%\ifthenelse{\boolean{ismanus}}{
	%	}{
		\begin{titlepage}
			\maketitle
			\begin{abstract}
				Self-selection into prospective cohort studies and loss to follow up can cause biased exposure-outcome association estimates. Previous investigations illustrated that such biases can be small in large prospective cohort studies. The structural approach to selection bias shows that general statements about bias are not possible for studies that investigate multiple exposures and outcomes, and that inverse probability of participation weighting (IPPW) but not adjustment for participation predictors generally reduces bias from self-selection and loss to follow up. A central condition for the manifestation of selection bias is that participation predictors also influence the outcome of interest, or that both have a common unobserved cause.  We propose to substantiate assumptions about common unobserved causes through calculation of genetic correlations coefficients between participation predictors and outcome, and to estimate a lower bound for bias due to self-selection and loss to follow up by comparing effect estimates from IPP weighted and unweighted analyses. Using the example of risk factors for ADHD in the Norwegian Mother and Child Cohort Study, we find that genetic correlations between participation predictors, exposures, and outcome suggest the presence of bias. The comparison of exposure-outcome associations from regressions with and without IPPW revealed meaningful deviations between estimates. Assessment of bias for entire multi-exposure multi-outcome cohort studies is not possible. Instead, selection bias has to be assessed and controlled on a case-by-case basis.
			\end{abstract}
			
			
			The authors thank Eivind Ystr√∏m for discussing an earlier version of the research and the International Cannabis Consortium for providing GWAS summary statistics.
		\end{titlepage}
	%}


\section{Introduction}

The complex etiology of many disorders and ethical considerations often precludes experimental approaches to identifying their causes \cite{Rothman2008-sq}. When controlled experimentation is not possible, cohort studies can provide valuable insights \cite{Greenland2017-qr}. Prospective cohort studies are particularly valuable, because participants enroll before the outcome of interest has occurred. Still, in prospective cohort studies selection bias is possible when the study sample is not a random sample from the population \cite{Hernan2004-oz}. Indeed, participation in cohort studies depends on socio-demographic factors \cite{Galea2007-hv}. Hence, recent research investigated bias in exposure-outcome association estimates from large population-based prospective cohort studies empirically, by comparing associations in the study sample with those in the target population \cite{Nilsen2009-ci, Nohr2006-uf, Nohr2018-sn, Hatch2016-us}.
A related study assessed bias due to loss to follow up by comparing association estimates from inclusion and follow up participants \cite{Greene2011-am}. A limitation of this empirical approach to detecting selection bias is that it can only evaluate bias when exposure and outcome data for the whole population is available.

The structural approach to selection bias uses directed acyclic graphs (DAGs \cite{Pearl1995-ss}) to explain the manifestation of bias. It requires information about participation predictors, for example age and education, and their relationship with exposure and outcome. Selection bias manifests if participation or participation predictors are colliders on the causal path between exposure and outcome \cite{Cole2010-za}. \citeauthor{Hernan2004-oz} \cite{Hernan2004-oz} showed that even when there is no direct path from participation predictors to outcome, common unobserved causes of participation predictors and outcome lead to selection bias. This manifests if, in addition, the exposure causes participation or if it causes or shares a common cause with participation predictors (see Figure \ref{fig:f1a} and \ref{fig:f1b}). In the absence of common effects and unobserved common causes, selection bias can still emerge due to effect modification, i.e. when population subgroups have varying participation rates and varying exposure-outcome associations (see Figure \ref{fig:f1c}).

\begin{figure}[h]
	\centering
	\ifthenelse{\boolean{ismanus}}{\input{figures/SelectionBiasEmpty}}{
		\resizebox{!}{4cm}{
			\input{figures/SelectionBias}
		}
	}
	\caption{Structural models of bias due to self-selection or loss to follow up in prospective cohort studies. A spurious association can manifests when participation $P$ or participation predictors $L$ are colliders on the path between exposure $E$ and outcome $D$. \protect\circled{$P$} indicates conditioning on $P$, which opens a collider, resulting in selection bias. Panel (a) depicts a situation where $L$ and $E$ are independent as long as there is no conditioning on $P$. Inverse probability of participation weighting (IPPW), direct standardization (DS) and multilevel regression and poststratification (MRP), or adjusting for $L$ (AR) reduce this type of selection bias. (b) When $E$ and $L$ share an unobserved common cause, selection bias can only be reduced with IPPW. Panel (c) depicts bias due to effect modification, which can manifest in the absence of unobserved causes or conditioning on a collider. IPPW, DS, MRP reduce this type of selection bias. (Panels (a) and (b) modified from \cite{Hernan2004-oz}).}
	\label{fig:SelectionBias}
\end{figure}


Figure 1 highlights that bias due to self-selection and loss to follow up depends on the relationship of variables included in an analysis with each other and with unobserved causes. Therefore, the presence or absence of bias cannot be determined for an entire cohort study that measures different exposures and outcomes. Instead, it has to be determined for each exposure-outcome-pair. Acquiring information about associations that determine selection bias is non-trivial, because \emph{unobserved} common causes of participation predictors and outcome are central. 

Common causes can be of environmental \cite{Johnson2011-wi,Verweij2013-xk} or genetic nature. Without presuming  that common genetic causes carry more weight than environmental factors, we propose to use the more readily widely reported genetic correlation coefficients ($r_G$) from twin \cite{Tambs2012-km} and genome wide association studies \cite{Bulik-Sullivan2015-er} as an indicator for common unobserved causes. For instance, \citeauthor{Bulik-Sullivan2015-xn} \cite{Bulik-Sullivan2015-xn} report single nucleotide polymorphism (SNP) based genetic correlations of $r_{G_{SNP}}=0.01$ and $0.731$ between education in adulthood and birth-weight or childhood IQ, respectively. Hence, if one uses a study sample that over-represents well-educated mothers to examine associations of maternal depression with birth weight or childhood IQ, the latter association is more likely biased.

A limitation of the structural approach is that it provides no estimate of selection bias--magnitude. Still, the comparison of association estimates obtained with and without correction for self-selection into continued participation can serve as a lower bound estimate of bias. Selection bias can be reduced by adjusting for participation predictors (adjusted regression, AR), by direct standardization with respect to participation predictors (DS \cite{Miettinen1972-vf}) or multilevel regression and poststratification (MRP \cite{Downes2018-oa}), and by weighting participants according to the inverse participation-probability (IPPW \cite{Seaman2013-rj}). While IPPW reduces all types of selection bias displayed in Figure \ref{fig:SelectionBias}, provided participation can be predicted well, DS and MRP reduce bias due to effect modification and structural bias when the exposure does not cause or share a common cause with participation predictors (as in Figures \ref{fig:f1a} and \ref{fig:f1c}). AR only reduces bias when the exposure does not cause or share a common cause with participation predictors (as in Figure \ref{fig:f1a}). AR, DS, and MRP cannot reduce selection bias when the exposure causes or shares a common cause with participation predictors (as in Figure \ref{fig:f1b}) because conditioning on a collider introduces bias \cite{Cole2010-za}.

In sum, this article proposes to evaluate selection bias in two steps. First, assumptions about common causes in causal models of exposure-outcome association and study participation should be substantiated, for example with estimates of genetic correlations. Second, a lower bound of selection bias magnitude can be estimated by comparing association estimates from IPPW and non-weighted analyses. In the remainder of the article we use the association between parental characteristics (exposures) and preschoolers' Attention deficit Hyperactivity Disorder (ADHD) symptoms (outcome) in the Norwegian Mother and Child Cohort Study (MoBa) as an example to demonstrate assessment of bias due to self-selection and loss to follow up in a large prospective cohort study. We estimate the joint effects of self-selection and loss to follow up by assessing bias in the study sample for which outcome data is available, because both biases are present in longitudinal studies. \emph{Note that in the remainder of the article "bias" refers exclusively to bias due to self-selection and loss to follow up, and not to any other type of bias.}

\section{Methods}

\subsection{Target population and study sample}

\paragraph{Study sample} MoBa is a prospective population-based pregnancy cohort study conducted by the Norwegian Institute of Public Health  \cite{Magnus2006-jj,Magnus2016-ht}. Participating mothers from all over Norway were recruited during routine ultrasound assessment in week 17 or 18 of their pregnancy in the period from 1999 to 2009. 41\% of the invited women consented to participation. MoBa participants received questionnaires in gestational week 17 or 18, week 22 and week 30, at child's age 6 and 18 months, 3, 5, and 8 years and onward. The study is still ongoing. The reported analyses also use information from the Medical Birth Registry of Norway (MBRN \cite{Irgens2000-ra}).

The current analysis uses data from the main inclusion period from January 2001 to December 2009, in which 94373 mothers returned the first MoBa questionnaire around the 20th pregnancy week. Of these 55763 (59\%) also returned the 6th MoBa questionnaire (at child age 3 years). Table \ref{table:age_edu} shows the bivariate distribution of age and education in the MoBa sample and the target population, i.e. women in Norway who gave birth in the sampling period.

\begin{table}[ht]
	\ifthenelse{\boolean{ismanus}}{}{\input{tables/age_edu_v9.tex}}
	\caption{Proportion of mothers split by age and education in study sample (n = 57478) and background population (n = 510556), as well as coverage (\% participation) of population subgroups in MoBa. Data for MoBa participants from MoBa and MBRN, population data were obtained from Statistics Norway. While around 30\% of mothers with a Master degree participated, only around 1\% of mothers with only elementary school education or less participated.} 
	\label{table:age_edu}
\end{table}

\paragraph{Participation predictors: Socioeconomic data about the target population}
We obtained aggregated data about age, educational level, and number of children for all women in the target population from Statistics Norway. 


\subsection{Statistical analysis}
R scripts for all analyses are available at {\footnotesize https://github.com/gbiele/IPW/tree/master/AnalysisBIPW}. A detailed description of the statistical methods is in the supplementary information.

\paragraph{Investigating unobserved common causes with LD score regression} We calculated genetic correlations between predictors of participation, exposures, and outcome from publicly available summary results of genome wide association studies (GWAS) using linkage disequilibrium (LD) score regressions \cite{Bulik-Sullivan2015-er}. Table \ref{tab:gwas} lists maternal phenotypes for which we obtained GWAS summary statistics. Maternal genetic correlations also inform about common causes of maternal and child phenotypes because mothers and their children share 50\% of their genes.

\paragraph{Outcome, exposures, and adjustment variables} We calculated an ADHD symptom score by summing the responses (Not, Somewhat, or Very often true, coded as 0, 1, 2) to 11 questions about ADHD symptoms that mothers' answered when the child was around 3 years old. Three separate analyses examined the magnitude of selection bias when estimating the association of (a) birth-related exposures, (b) maternal and paternal use of legal drugs, and (c) maternal and paternal mental health including use of illegal drugs with preschoolers' ADHD score. Table \ref{table:variables} describes the variables used in the analyses. 

MoBa assessed parental mental health with short forms of the symptom checklist (SCL5, \cite{Tambs1993-ch}), the lifetime history of depression questionnaire (LTH, \cite{Kendler1993-pf}), and the ADHD Self-Report Scale (ASRS, \cite{Kessler2007-et}). MoBa measured use of illegal drugs (cannabis, ecstasy, amphetamines, cocaine; less than 0.01\% indicated  having used heroin) before or in the pregnancy with Likert scales. As a dimensional measure of illegal drug-use we used ability scores from an item response theory analysis \cite{Rizopoulos2006-bc}. 


\begin{table}[ht]
	\centering
	\ifthenelse{\boolean{ismanus}}{}{\input{tables/variables}}
	\caption{Description of variables and their use.
		\newline m. = maternal, p. = paternal, Q = MoBa questionnaires, Q1 = at pregnancy week 17, QF = for fathers' (week 20), Q6 = at child age 3, MBRN = Medical Birth Registry of Norway, SS = sum score. Scale for maternal drinking frequency: 0 = Never , 0.5 = $<$1 per month, 2 =  $\le$1. All other continuous and count variables except parity scaled to a mean of zero and a standard deviation of one. I = used in IPPW model, A = AR model, U = UR model, I$_S$ in selection model for IPPWs calculation, not for adjustment in IPPW model.} 
	\label{table:variables}
\end{table}


All presented analyses used participants for which at least 50\% of the analysis variables were available. We created 20 multiply imputed data sets through multiple imputation by chained equations as implemented in the R package mi \cite{Su2011-he}. 

\paragraph{IPPWs and bias estimation}

We calculated stabilized inverse probability weights using tabulated data about education, age and number of children for all birth giving mothers in Norway in the sampling period of MoBa. Because we rely on tabulated data, we used a binomial regression to estimate participation probabilities for population subgroups. We used a hierarchical regression with random intercepts and slopes for the effect of age in subgroups defined by education and parity, in order to estimate effects of age also in small sub-groups reliably.


The estimation of a lower bound for bias involves estimating an IPPW and alternative regression models. The IPPW model estimates weighted and adjusted exposure outcome associations. The AR model, following typical practice for the analysis of cohort studies, adjusts for participation predictors instead of using IPPWs. The unadjusted regression (UR) does no adjustment and uses no IPPWs (c.f. Tables \ref{table:variables} and \ref{tab:regmodels}). To account for covariation of regression weights, we fit the three models simultaneously in a Bayesian framework, and define regression weights for exposures in the AR and UR models as weights from the IPPW model plus difference terms. Because ADHD sum scores are constraint between 0 and 22 we used a beta binomial regression model and report associations as average marginal effects (AMEs).

Based on this analysis model, we calculated the lower bound bias estimate as the difference between AMEs from the IPPW and AR or UR models, respectively. We standardised the lower bound bias by dividing the difference with either the standard deviation or the mean of the posterior distribution of the IPPW estimate (c.f. \cite{Stuart2010-cj,Nilsen2009-ci}). The latter approach appeals to the intuition that bias is problematic if the comparison standard is known with high precision/certainty, whereas the former appeals to the intuition that bias is problematic if it has a large deviation from the comparison standard. 

To test for bias, we check how much of the posterior distribution of the bias estimate lies within a region of practical equivalence (ROPE, dashed vertical lines in Figure \ref{fig:estimates}), i.e., a bias magnitude that is for practical purposes equivalent with zero \cite{Mascha2011-um}. Earlier research defined deviations of larger than 30\% or 40\% of the standard deviation or mean of comparison standard as problematic \cite{Stuart2010-cj,Nohr2006-uf}. Here, we consider values of less than 0.5 standardised AME differences as practically equivalent with zero. To obtain a measure of risk for bias we calculate the log of the ratio of the posterior distribution inside and outside the ROPE, $log(RR_b)$. For example, a $log(RR_b)$ of -1.6 (3) means that the lower bound bias estimate is five (20) times as likely to lie outside (inside) the ROPE.

Regression analyses were performed with custom models implemented in the probabilistic programming language Stan \cite{Stan_Development_Team2017-lp} and fit via RStan \cite{Stan_Development_Team_2018-rs}.

\section{Results}

Statistics Norway recorded 510\,561 women who became mothers in the period from 2001 to 2009. In the same period, 94\,373 mothers returned the first MoBa questionnaire (Q1). Of these, 55\,763 also returned the sixth questionnaire,  which was sent out when  children were 3 years old. 54\,557 returned questionnaires with fewer than 50\% missing data among the variables of interest. The study sample used for the reported analysis constitute around 14\% of the target population.

\subsection*{Socio-demographic composition of study sample and population}
 Mothers with elementary school education or less constitute around 18.7\% of the target population but only 1.7\% of the MoBa sample (c.f. Table \ref{table:age_edu}). 16.6\% of mothers in the target population are younger than 25, compared to around 9.1\% in the study sample. Accordingly, the participation rates vary substantially between population subgroups: 29.7\% of mothers with a master's degree are in the study sample, but only around 1\% of mothers with elementary school education. For parity, the difference between study sample and target population is less pronounced. The percentages of women in the target population (study sample) who had previously 0, 1, 2, or 3 or more children are 41.8 (50.9), 36.3 (32.5), 16.1 (13.9), 2.8 (5.8), respectively. Hence, the study sample over-represents mothers of firstborn children and under-represents those with more than two children.

\subsection*{Inverse probability weights}
The hierarchical binomial model captured participation well, as indicated by a correlation of $r=0.99$ between modelled and observed participation rates (see Figure \ref{fig:IPW}). Mothers' education was the key variable to predict participation. Stabilized weights ranged between on average 0.31 and 21.36. The largest weights were for mothers with only elementary school education, and the smallest for mothers with a master's degree. We chose not to trim extreme weights, because this would result in improper weighting of the study sample. While some weights are very large, the associated population subgroups are typically represented with more than  100 children in the study sample.

\subsection*{Unobserved common causes}
Genetic correlation results shown in Figure \ref{fig:rg} indicate unobserved common causes of participation predictors and outcome or exposures, respectively. For example, genes associated with "age at first birth" or "years of education" are also (negatively) associated with ADHD, maternal mental health, or smoking. The estimated SNP based overall heritability of the investigate phenotypes is typically not high, and often below 10\%.

\begin{figure}
	\begin{center}
		\ifthenelse{\boolean{ismanus}}{}{\input{figures/rg}}
	\end{center}
	\caption{Genetic correlations as predictors of common unobserved causes. $h^2_{SNP}$ = SNP based genetic heritability from LD score regression. $r_{G_{SNP}}$ = genetic correlation between two traits based on LD score regression from GWAS summary statistics. Square colors indicate direction and size of correlations, the size visualises z-values (which also depend on sample sizes). Gray square-outlines in the cells visualise the border to $|z|=4$ . The possibility of common causes of the participation predictors education and mothers age (AgeFirstBirth) and outcome ADHD cannot be excluded. Education and some exposures like maternal depressive symptoms or smoking also appear to have common genetic causes. Table \ref{tab:rg} lists all genetic correlations and heritability estimates.}
	\label{fig:rg}
\end{figure}

\subsection*{Selection bias for exposure-outcome associations}
Figure \ref{fig:estimates} and Table \ref{tab:estimatesAR} show AME estimates from an IPPW analysis that reduces selection bias (AME$_{IPPW}$), from an adjusted regression that only adjusts for participation predictors (AME$_{AR}$),and from an unadjusted regression (AME$_{UR}$). Results from the IPPW analysis show, consistent with the literature, that most risk factors were positively, albeit weakly, associated with the ADHD symptom sum-score. Maternal smoking had the strongest association: Mothers who indicated that they smoked, reported on average an ADHD symptom sum-score for their child that was around 0.5 points higher (on a scale from 0 to 22) than mothers' who indicated no smoking. Maternal drinking (frequency of alcohol use), maternal depressive symptoms (SCL5), and a low birth weight (SGA) were also relatively strongly associated with ADHD sum scores, whereas associations with paternal variables other than drug use were generally weaker.

We estimated a lower bound of selection bias as the difference between average marginal effects ($AME$) from the IPPW and AR or UR models, standardised by either the mean or the standard deviation of the IPPW estimates. Figure \ref{fig:estimates} and Tables \ref{tab:estimatesAR} and \ref{tab:estimatesUR} reveal little evidence for the absence of bias: For the AR model, only mean-standardised bias estimates for maternal depressive symptoms (SCL5, $log(RR_b)=4.5$) and maternal smoking in pregnancy (mSMOKE, $log(RR_b)=4.6$) are largely within the ROPE. There is clearer evidence for the presence of bias, in particular when standardising with the mean or standard deviation of the IPPW estimate. Most of these bias estimated lie largely outside the ROPE. 

While the highest density interval (HDI) of the lower bound bias estimates for the UR model lies only for few variables completely outside the ROPE, the risk ratio for having a bias larger than 0.5 for the AR model is higher than 20 (i.e. $log(RR_b) < -3$) for 11 variables when standardizing bias by the standard deviation of $AME_{IPPW}$ and for 5 variables when standardizing by the mean of $AME_{IPPW}$ (c.f. Table  \ref{tab:estimatesAR} and Figure \ref{fig:logRRsAR}). The results indicate both over-- and under--estimation of associations in the AR analysis (e.g. frequency of maternal alcohol use and paternal drug use). IPPW and AR results also differ categorically, in that sometimes the IPPW results provide evidence for an association while the AR results do not (e.g. paternal drug use) and sometimes the opposite (paternal cigarettes per day). 

\begin{figure}
	\centering
	\ifthenelse{\boolean{ismanus}}{}{\input{figures/estimates+raw}}
	\caption{Exposure-outcome association and bias. Left panel: AME = Average Marginal Effect for a one unit increase of the exposure (all exposures except parity standardised). 
	Middle and right panel: $\delta_{AR}$ ($\delta_{UR}$) are differences between adjusted (unadjusted) regression and IPPW estimates, standardised by mean ($\mu_{IPPW}$) or standard deviation ($\sigma_{IPPW}$) of the IPPW estimates. To confirm the absence of bias, the 90\% HDI should fall between the dashed vertical lines, which enclose the region of practical equivalence with zero (ROPE). The ROPE contains standardised $\delta$s of less than 0.5. Bias estimates or HDIs outside the x-axis limits ($-7.5$, $+5$) are marked with $<$ or $>$  symbols.}
\label{fig:estimates}
\end{figure}

\begin{table}
	\ifthenelse{\boolean{ismanus}}{}{\input{tables/estimates-AR.tex}}
	\caption{Means and 90\% highest density intervals (HDIs) of exposures outcome associations and standardised bias of AR and UR results. $AME_{IPPW}$, $AME_{AR}$: Average marginal effects from IPPW, and AR models, respectively. $\sigma_{IPPW}$ and $\mu_{IPPW}$ are standard deviation and mean of the posterior distribution of the IPPW regression coefficients. See table \ref{tab:estimatesUR} for statistics for the UR model.} 
	\label{tab:estimatesAR}
\end{table}



\section{Discussion}
Bias due to self-selection into studies and loss to follow-up is a threat to the validity of exposure-outcome association estimates from prospective cohort studies, because these often over-represent well educated, resourceful segments of the target population (Table \ref{table:age_edu}, see also \cite{Vinther-Larsen2010-hq, Galea2007-hv, Howe2013-vv}). The structural approach to selection bias highlights that selection bias depends on the involved variables \cite{Hernan2004-oz}. Therefore, it is not possible to evaluate selection bias generally for cohort studies that assess multiple exposures and outcomes. Among the statistical approaches to control bias, inverse probability of participation weighting (IPPW) is more generally able to correct bias than adjusted regression or direct standardization \cite{Hernan2004-oz}.

Using risk factor for ADHD as an example, we found that genetic correlations between participation predictors, exposures and outcome indicate potential bias, when maternal education predicts study participation. The analysis of associations between risk factors and ADHD in MoBa revealed substantial differences between association estimates obtained with IPPW and those obtained with adjustment for participation predictors (AR) or no adjustment (UR). Only in few instances (mean standardised bias of associations with maternal smoking and LTH score) was there clear evidence against the presence of bias due to self-selection and loss to follow up.

The current study reports more evidence for the presence of bias due to self-selection and loss to follow up than previous investigations of large prospective cohort studies \cite{Nilsen2009-ci, Nohr2006-uf,Greene2011-am, Wolke2009-lu}. Whereas previous reports used association estimates from the target population as a comparison standard for estimates from the study sample, this study used IPPW estimates. The validity of IPPW estimates as comparison standard depends on how well participation predictors predict participation \cite{Seaman2013-rj}. In our study, the selection model predicted participation well. Another potential explanation for the stronger evidence for bias in our study is that bias in study samples at the onset of cohort studies is smaller because participation rates are higher. Further, because the heritability of ADHD is estimated to be higher compared to birth-related outcomes (c.f. Figure \ref{fig:rg} and \cite{Wu2015-bg}), selection bias due to common unobserved causes of participation predictors and outcome is expected to be larger for ADHD. Indeed, the strongest evidence for bias from earlier investigations comes from the association between maternal smoking and child ADHD \cite{Greene2011-am}. Lastly, whereas previous studies evaluated bias by testing for significant difference between sample and population estimates, equivalence testing \cite{Schuirmann1987-ip, Mascha2011-um} is the proper approach to test if two association estimates are equal. Therefore, previous analyses provided little statistical evidence for the absence of bias. 

While the presented results indicate the presence of bias, one could reason that this is largely inconsequential, because the weighted and un-weighted association estimates typically point in the same direction. However, it is also important to recognise that in some cases the weighted and unweighted analyses led to categorically different conclusions. Crucially, in translational research, the magnitude of an association is also important, so that not only non-detection of effects, but also errors in the estimation of effect sizes are problematic \cite{Sullivan2012-uc}.

Conclusions about the presence or seriousness of bias can depend on how bias estimates are standardised or by how wide the ROPE is. Typically, bias estimates are standardised by the standard deviation of the unbiased parameter estimate \cite{Stuart2010-cj}, which we here replaced with the standard deviation of the corrected (IPPW) estimate. Similar to \citeauthor{Nilsen2009-ci} \cite{Nilsen2009-ci} we also estimated the percent deviation from the comparison standard, and found that this mean-standardised bias estimates was generally smaller. It is difficult to determine generally how large a bias is problematic, which should depend on the subject matter. We defined standardised deviations of less than 50\%  as practically equivalent with zero, which is higher than the 30\% or 40\% as thresholds used in previous studies \cite{Greene2011-am, Stuart2010-cj}, and still found clear evidence for bias.

Earlier assessments of bias in cohort studies that compared association estimates from study sample and target population are elegant in that their validity does not depend on assumptions about the causal relationship of exposure, outcome, and participation predictors. However, if population data about exposure and outcome are available, exposure-outcome-associations need not be estimated from smaller study samples, and estimation of selection bias is superfluous. Using results from an IPPW regression as comparison standard rests on the assumption that the weighted study sample is a good representation of the target population, which is only the case if participation can be predicted well \cite{Seaman2013-rj}. We found a high correspondence between predicted and observed participation rates, which suggests that the weighted MoBa sample represents the target population well. To verify that the test of the assumption is falsifiable, one can hypothesise a scenario that would have resulted in a violation. For example, if participation also strongly depended on maternal birth month, a selection model that uses only socio-demographic predictor-variables would not predict participation well.  Still, when calculating participation probabilities for population sub-groups, it remains possible that some bias results from within-group selection-bias, if there exist unmeasured participation predictors L, that are independent of the measured predictors. This appears unlikely in the current analysis, because the key participation predictor education is strongly associated with unmeasured predictors like mental health.

The reliability of IPPW estimates also depends on the number of study-participants in population subgroups, especially if only few members of large population sub-groups participate in a study sample. However the low reliability of IPPW estimates in such circumstances, may indicate a weaknesses of the sampling strategy rather than a weakness of the IPPW.
The IPPW discussed in the current research are appropriate for relatively simple studies without time varying treatments or time to event analysis. For studies with such characteristics, more advanced weighting schemes like inverse probability of censoring weights (IPCW\cite{Robins2000-fq}) need to be employed.

While IPPW can remove bias due to self-selection and loss to follow up, it cannot remove bias from unmeasured confounders. This is reflected in our finding of an association between maternal smoking and ADHD, which is likely due to familial genetic or environmental confounders \cite{Donovan2011-me}. While bias due to unmeasured confounders would also be present in an analysis based on data from the whole population, it is important to emphasise that other biases than bias due to self-selection and loss to follow up can still be present in estimates obtained with IPPW.  

Structural analysis highlights that bias depends specifically on the involved variables, such that the presence or amount of bias for one association does not generalise to other associations. Still, structural analysis describes under which conditions bias manifests. A first condition for bias to emerge is the presence of common unobserved causes of participation predictors like education and the outcome. A second condition is a direct or indirect causal relationship between participation predictors and the exposure. Figure \ref{fig:rg} shows that genes (or associated environmental characteristics) can be common unobserved causes of mental health outcomes and the participation predictor education, and of education and exposures like smoking. It is therefore probable that non-weighted estimates of associations between e.g. maternal mental health, smoking or drinking behavior, and mental health related outcomes are biased in studies that over-represent certain educational groups. Importantly, this hypothesis only suggests that bias is likely, whereas the actual presence and magnitude of bias is unknown and has to be examined in individual studies. 

\begin{figure}
	\centering
	\begin{singlespace}
	\ifthenelse{\boolean{ismanus}}{}{\input{figures/decision_trees}}	
    \end{singlespace}
	
	%\input{figures/decision_tree}
	\caption{Decision tree for identification of selection bias and choice of approach to correct it. See Figure \ref{fig:SelectionBias} for causal diagrams that underlie the decision tree. 
	To determine if selection bias is likely, and if so which correction method can be used, proceed through the questions from the top on. Ending in a node "Bias is unlikely" implies that an  analysis without correction for selection bias will still result in estimates with out selection bias. Otherwise, different correction types can be used, depending on the underlying causal structure. IPPW stands for analysis with inverse probability of participation weighting, AR for adjusted regression. For reasons of brevity, this decision tree does not isolate cases where multilevel regression and post stratification (MRP) can be used to correct bias. }
	\label{fig:DecisionTree}
\end{figure}


Structural analysis using directed acyclic graphs (DAGs) is a useful tool for the development of analysis strategies that remains underused. A practical argument against the use of DAGs is the uncertainty about hypothesised causal relationships. We proposed to use genetic correlation coefficients from LD score regression of publicly available GWAS summary statistics as one possibility to substantiate central assumptions about unobserved common causes. The main motivation to focus on common genetic causes is the growing availability of GWAS summary statistics and methodological advances allowing estimation of heritability and genetic correlation coefficients from such statistics \cite{Bulik-Sullivan2015-er, Bulik-Sullivan2015-xn}. Because GWAS studies are association studies, they do not provide unambiguous proof for a causal role of genes. Still, even if GWAS associations estimates are partly driven by environmental factors, genetic correlation estimates from GWAS summary statistics are of interest because common environmental causes also contribute to the manifestation of selection bias. Indeed, if direct estimates of common environmental causes are available, they should also be used when evaluating DAGs

A second challenge when using structural models is the difficulty of formulating DAGs for complex causal models \cite{Shrier2008-vr}. When judging the presence of bias due to self-selection and selective dropout, a simple decision tree can supplant the formulation of a complete DAG, so that researchers can determine the potential for selection bias by answering a sequence of questions about the relationship of participation predictors, exposures, and outcomes. Figure \ref{fig:DecisionTree} shows a decision tree that identifies when correction for bias is necessary, and what correction method is appropriate.

A topic closely related to selection bias is that of representativeness. While it was argued that representativeness can be detrimental to scientific inference, because understanding of mechanisms and careful control of relevant variables are central for this aim \cite{Rothman2013-qc}, others have emphasised the importance of representativeness---understood as the availability of weights for calculating valid population estimates \cite{Keiding2016-fv}. Careful experimentation based on hypothesised mechanisms is undoubtedly central to scientific progress. Still, this approach does not describe the often-exploratory analyses of cohort study data well. Moreover, if one understands causal inference as the central goal of scientific inquiry, ignoring non-representativeness of unweighted study samples does not only undermine generalization to the population of interest, but can also lead to incorrect scientific inferences by facilitating the "discovery" of associations where there are in fact none, or prevent the detection of existing associations.

In conclusion, self-selection into cohort studies and loss to follow up can lead to biased estimates of exposure-outcome associations from large population based cohort studies. Structural analysis and empirical results suggest that especially for mental health related exposures and outcomes selection bias is likely. Still, the dependency of bias on the specific outcome, exposure, and study participation predictors makes general statements about selection bias for multi-exposure multi-outcome studies impossible. Instead, each  investigation of an exposure-outcome association has to assess selection bias. If bias is likely and valid participation predictors are available, weighting study participants by the inverse of their participation probability is a robust approach to control bias due to self-selection and loss to follow up.


Funding: This study was funded by the Norwegian Institute of Public Health.


Conflict of Interest: The authors declare that they have no conflict of interest.


\newpage

\printbibliography

\newpage

\processdelayedfloats

\clearpage

\makeatletter
\efloat@restorefloats
\makeatother

\appendix

\renewcommand{\thefigure}{S\arabic{figure}}
\renewcommand{\thepostfigure}{S\arabic{postfigure}}
\setcounter{figure}{0}
\setcounter{postfigure}{0}

\renewcommand{\thetable}{S\arabic{table}}
\renewcommand{\theposttable}{S\arabic{posttable}}
\setcounter{table}{0}
\setcounter{posttable}{0}

%\begin{comment}

\phantomsection{Supplementary Information}
\setcounter{page}{1}

\phantomsection{Supplementary tables}

\begin{table}
	\caption{}
	\label{tab:regmodels}
\end{table}

\begin{table}
	\caption{}
	\label{tab:gwas}
\end{table}

\begin{table}
	\caption{}
	\label{tab:rg}
\end{table}

\begin{table}
	\caption{}
	\label{tab:estimatesUR}
\end{table}

\phantomsection{Supplementary figures}

\begin{figure}[ht]
	\caption{}
	\label{fig:prop_moba_ssb}
\end{figure}

\begin{figure}[ht]
	\caption{}
	\label{fig:covariation}
\end{figure}

\begin{figure}[ht]
	\caption{}
	\label{fig:IPW}
\end{figure}

\begin{figure}[ht]
	\caption{}
	\label{fig:IPWbalance}
\end{figure}


\begin{figure}[ht]
	\caption{} 
	\label{fig:logRRsAR}
\end{figure}

\begin{figure}[ht]
	\caption{} 
	\label{fig:logRRsUR}
\end{figure}

\begin{figure}[ht]
	\caption{}
	\label{fig:ropeplotsAR}
\end{figure}

\begin{figure}[ht]
	\caption{}
	\label{fig:ropeplotsUR}
\end{figure}

%\end{comment}

\end{document}
